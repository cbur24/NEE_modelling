{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate and fit a ML model on the EC flux tower data \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shap\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import seaborn as sb\n",
    "from joblib import dump\n",
    "import multiprocessing\n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "# from lightgbm import LGBMRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import lightgbm as lgbm\n",
    "from sklearn.model_selection import LeaveOneGroupOut, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "import sys\n",
    "sys.path.append('/g/data/os22/chad_tmp/dea-notebooks/Tools')\n",
    "from dea_tools.classification import spatial_clusters\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'AUS'\n",
    "model_var = 'NEE'\n",
    "\n",
    "scoring='neg_mean_absolute_error'\n",
    "cluster_method = 'Hierarchical'\n",
    "max_distance = 0.0000001 # map degrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncpus=multiprocessing.cpu_count()\n",
    "print('ncpus = '+str(ncpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = '/g/data/os22/chad_tmp/NEE_modelling/results/training_data/'\n",
    "sites = os.listdir('/g/data/os22/chad_tmp/NEE_modelling/results/training_data/')\n",
    "\n",
    "td = []\n",
    "for site in sites:\n",
    "    if '.csv' in site:\n",
    "        xx = pd.read_csv(base+site, index_col='time', parse_dates=True)\n",
    "        xx['site'] = site[0:5]\n",
    "        td.append(xx)\n",
    "\n",
    "ts = pd.concat(td).dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = [\n",
    "            #'LAI_anom_RS',\n",
    "             'kNDVI_anom_RS',\n",
    "             'FPAR_RS',\n",
    "             'LST_RS',\n",
    "             'tree_cover_RS',\n",
    "             'nontree_cover_RS',\n",
    "             'nonveg_cover_RS',\n",
    "             'LST-Tair_RS',\n",
    "             'TWI_RS',\n",
    "             'NDWI_RS',\n",
    "             'rain_anom_RS',\n",
    "             'rain_cml3_anom_RS',\n",
    "             'rain_cml6_anom_RS',\n",
    "             'rain_cml12_anom_RS',\n",
    "             'srad_anom_RS',\n",
    "             'vpd_RS',\n",
    "             'tavg_anom_RS',\n",
    "             'SOC_RS',\n",
    "             #'CO2_RS',\n",
    "             #'site'\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = []\n",
    "yy = []\n",
    "cc = []\n",
    "dfs = []\n",
    "for t in td:\n",
    "    # t = t.drop('PFT_RS', axis=1)\n",
    "    t = t.dropna()  # remove NaNS\n",
    "    coords = t[['x_coord','y_coord']] #extract coords\n",
    "    t = t.drop(['x_coord','y_coord','site'] , axis=1) # drop coords and Landcover\n",
    "    df = t.drop(['NEE_SOLO_EC','GPP_SOLO_EC','ER_SOLO_EC'], axis=1) # seperate carbon fluxes\n",
    "    \n",
    "    #df = df.filter(regex='RS') # only use remote sensing variables   \n",
    "    df = df[variables]\n",
    "\n",
    "    if model_var == 'ET':\n",
    "        df_var=t[model_var+'_EC']\n",
    "    else:\n",
    "        df_var=t[model_var+'_SOLO_EC'] # seperate out the variable we're modelling\n",
    "\n",
    "    x = df.reset_index(drop=True)#.to_numpy()\n",
    "    y = df_var.reset_index(drop=True)#.to_numpy()\n",
    "    c = coords.reset_index(drop=True)\n",
    "    xx.append(x)\n",
    "    yy.append(y)\n",
    "    cc.append(c)\n",
    "    \n",
    "x = np.concatenate([x for x in xx])\n",
    "y = np.concatenate([y for y in yy])\n",
    "c = np.concatenate([c for c in cc])\n",
    "\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test model robustness with nested spatial leave-one-group-out cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualising spatial groupings\n",
    "\n",
    "After setting the parameters, lets first generate spatial clusters using the DE Africa function spatial_clusters to visualize how our data will be grouped when running SKCV in the next step. You may want to refine the parameters to achieve a grouping that works for your dataset by resetting the parameters above\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aus=gpd.read_file('/g/data/os22/chad_tmp/NEE_modelling/data/aus_outline/AUS_2021_AUST_GDA2020.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create clustes\n",
    "spatial_groups = spatial_clusters(coordinates=c,\n",
    "                                  method=cluster_method,\n",
    "                                  max_distance=max_distance,\n",
    "                                  n_groups=None,\n",
    "                                  verbose=True)\n",
    "\n",
    "#plot\n",
    "fig, ax = plt.subplots(1,1, figsize=(10,6))\n",
    "aus[aus.AUS_CODE21=='AUS'].plot(ax=ax, color='lightgrey')\n",
    "ax.scatter(c[:, 0], c[:, 1], c=spatial_groups,\n",
    "            s=50, cmap='tab20');\n",
    "ax.set_xlim(110,155)\n",
    "plt.title('Spatial clusters of training data');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create outer k-fold splits\n",
    "outer_cv = LeaveOneGroupOut()\n",
    "\n",
    "acc = []\n",
    "rmse=[]\n",
    "r2=[]\n",
    "i = 1\n",
    "for train_index, test_index in outer_cv.split(x, y, spatial_groups):\n",
    "    print(f\"Working on {i}/{len(np.unique(spatial_groups))} split\", end='\\r')\n",
    "    \n",
    "    model = RandomForestRegressor()\n",
    "    # model = LGBMRegressor(random_state=1, n_jobs=ncpus)\n",
    "\n",
    "    # index training, testing, and coordinate data\n",
    "    X_tr, X_tt = x[train_index, :], x[test_index, :]\n",
    "    y_tr, y_tt = y[train_index], y[test_index]\n",
    "    inner_groups = spatial_groups[train_index]\n",
    "    \n",
    "    # inner split on data within outer split\n",
    "    # inner_cv = LeaveOneGroupOut()\n",
    "    \n",
    "    #print(inner_cv.get_n_splits(X_tr, y_tr, inner_groups))\n",
    "#     clf = GridSearchCV(\n",
    "#         estimator=model,\n",
    "#         param_grid=param_grid,\n",
    "#         scoring=scoring,\n",
    "#         n_jobs=ncpus,\n",
    "#         refit=True,\n",
    "#         cv=inner_cv.split(X_tr, y_tr, inner_groups),\n",
    "#     )\n",
    "\n",
    "#     clf.fit(X_tr, y_tr)\n",
    "    \n",
    "#     # predict using the best model\n",
    "#     best_model = clf.best_estimator_\n",
    "#     pred = best_model.predict(X_tt)\n",
    "    \n",
    "    model = model.fit(X_tr, y_tr)\n",
    "    pred = model.predict(X_tt)\n",
    "\n",
    "    # evaluate model w/ multiple metrics\n",
    "    X_ = sm.add_constant(y_tt)\n",
    "    model = sm.OLS(pred,X_)\n",
    "    r2_ = model.fit().rsquared\n",
    "    r2.append(r2_)\n",
    "    ac = mean_absolute_error(y_tt, pred)\n",
    "    acc.append(ac)\n",
    "    rmse_ = np.sqrt(mean_squared_error(y_tt, pred))\n",
    "    rmse.append(rmse_)\n",
    "    \n",
    "    #Compare time-series in a plot\n",
    "    df_y_true = ts.iloc[test_index]\n",
    "    df_y_true['pred_'+model_var] = pred \n",
    "    sb.set_style(\"darkgrid\")\n",
    "    fig,ax = plt.subplots(1,1, figsize=(12,5))\n",
    "    sb.lineplot(x='time', y=model_var+'_SOLO_EC', data=df_y_true, color=\"green\", linewidth=1, ax=ax)\n",
    "    sb.lineplot(x='time', y='pred_'+model_var, data=df_y_true, color=\"blue\", linewidth=1, ax=ax)\n",
    "\n",
    "    ax.text(.015, .95, 'r = {:.3f}'.format(r2_),\n",
    "            transform=ax.transAxes)\n",
    "    ax.text(.015, .9, 'mae = {:.3g}'.format(ac),\n",
    "            transform=ax.transAxes)\n",
    "\n",
    "    ax.set_ylabel(model_var)\n",
    "    ax.set_xlabel(None)\n",
    "    ax.set_title(df_y_true['site'][0]+': '+model_var + ' Cross Validation Results')\n",
    "    plt.legend(labels=[\"True\",\"Prediction\"], loc='lower left')\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(\"/g/data/os22/chad_tmp/NEE_modelling/results/cross_validation/\"+df_y_true['site'][0]+\"_\"+model_var+\".png\")\n",
    "    plt.close()\n",
    "    \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean MAE accuracy: \"+ str(round(np.mean(acc), 2)))\n",
    "print(\"Std dev of MAE accuracy: \"+ str(round(np.std(acc), 2)))\n",
    "print('\\n')\n",
    "print(\"Mean RMSE: \"+ str(round(np.mean(rmse), 2)))\n",
    "print(\"Std dev RMSE: \"+ str(round(np.std(rmse), 2)))\n",
    "print('\\n')\n",
    "print(\"Mean r2: \"+ str(round(np.mean(r2), 2)))\n",
    "print(\"Std dev r2: \"+ str(round(np.std(r2), 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.min(r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.max(r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the parameter grid based\n",
    "param_grid = {\n",
    "    'num_leaves': [7, 14, 21, 28, 31, 50],\n",
    "    'min_data_in_leaf':[15, 20, 30],\n",
    "    #'boosting_type ': ['gbdt', 'dart'],\n",
    "    'max_depth': [3, 5, 10, 20],\n",
    "    'n_estimators': [100, 200, 300, 400],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#generate n_splits of train-test_split\n",
    "logo = LeaveOneGroupOut()\n",
    "\n",
    "#instatiate a gridsearchCV\n",
    "clf = GridSearchCV(LGBMRegressor(),\n",
    "                   param_grid,\n",
    "                   scoring=scoring,\n",
    "                   verbose=1,\n",
    "                   cv=logo.split(x, y, spatial_groups),\n",
    "                   n_jobs=ncpus)\n",
    "\n",
    "clf.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The most accurate combination of tested parameters is: \")\n",
    "pprint(clf.best_params_)\n",
    "print('\\n')\n",
    "print(\"The best score using these parameters is: \")\n",
    "print(round(clf.best_score_*-1, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit on all data using best params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LGBMRegressor(**clf.best_params_, random_state=1, n_jobs=ncpus)\n",
    "model.fit(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine feature importance\n",
    "\n",
    "SHAP (SHapley Additive exPlanations) is a game theoretic approach to explain the output of any machine learning model\n",
    "\n",
    "https://github.com/slundberg/shap\n",
    "\n",
    "https://towardsdatascience.com/explaining-scikit-learn-models-with-shap-61daff21b12a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explain the model's predictions using SHAP\n",
    "explainer = shap.Explainer(model)\n",
    "shap_values = explainer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add names of features\n",
    "shap_values.feature_names = df.columns.values\n",
    "\n",
    "# visualize the importances\n",
    "# shap.plots.waterfall(shap_values[0])\n",
    "# shap.plots.beeswarm(shap_values)\n",
    "shap.plots.bar(shap_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(model, '/g/data/os22/chad_tmp/NEE_modelling/results/models/'+model_name+'_'+model_var+'_RF_LOGO_model.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict on all the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x)\n",
    "\n",
    "rmse = float(format(np.sqrt(mean_squared_error(y, y_pred)), '.3f'))\n",
    "print(\"RMSE:\", rmse);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.scatterplot(x=y,y=y_pred,color=\"#338844\", edgecolor=\"white\", s=50, lw=1, alpha=0.5)\n",
    "sb.regplot(x=y, y=y_pred, scatter=False, color='m')\n",
    "sb.regplot(x=y, y=y, color='black', scatter=False, line_kws={'linestyle':'dashed'});\n",
    "plt.xlabel('True')\n",
    "plt.ylabel('Prediction');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
