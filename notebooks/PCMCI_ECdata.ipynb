{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Causal discovery with `TIGRAMITE`\n",
    "\n",
    "TIGRAMITE is a time series analysis python module. It allows to reconstruct graphical models (conditional independence graphs) from discrete or continuously-valued time series based on the PCMCI framework and create high-quality plots of the results.\n",
    "This tutorial explains the main features in walk-through examples. It covers:\n",
    "\n",
    "1. Basic usage\n",
    "2. Plotting\n",
    "3. Nonlinear conditional independence tests\n",
    "4. Symbolic time series\n",
    "\n",
    "PCMCI is described here:\n",
    "J. Runge, P. Nowack, M. Kretschmer, S. Flaxman, D. Sejdinovic, \n",
    "Detecting and quantifying causal associations in large nonlinear time series datasets. Sci. Adv. 5, eaau4996 (2019) \n",
    "https://advances.sciencemag.org/content/5/11/eaau4996\n",
    "\n",
    "For further versions of PCMCI (e.g., PCMCI+, LPCMCI, etc.), see the corresponding tutorials.\n",
    "\n",
    "See the following paper for theoretical background:\n",
    "Runge, Jakob. 2018. “Causal Network Reconstruction from Time Series: From Theoretical Assumptions to Practical Estimation.” Chaos: An Interdisciplinary Journal of Nonlinear Science 28 (7): 075310.\n",
    "\n",
    "Last, the following Nature Communications Perspective paper provides an overview of causal inference methods in general, identifies promising applications, and discusses methodological challenges (exemplified in Earth system sciences): \n",
    "https://www.nature.com/articles/s41467-019-10105-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import sklearn\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline     \n",
    "\n",
    "import tigramite\n",
    "from tigramite import data_processing as pp\n",
    "from tigramite.toymodels import structural_causal_processes as toys\n",
    "from tigramite import plotting as tp\n",
    "from tigramite.pcmci import PCMCI\n",
    "from tigramite.independence_tests import ParCorr, GPDC, CMIknn, CMIsymb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis Paramaters\n",
    "\n",
    "Tumbarumba/2022_v1/L6/default/Tumbarumba_L6_20020107_20191231_Daily.nc\n",
    "\n",
    "'AliceSpringsMulga/2022_v1/L6/default/AliceSpringsMulga_L6_20100903_20211231_Daily.nc'\n",
    "\n",
    "AliceSpringsMulga/2022_v1/L6/default/AliceSpringsMulga_L6_20100903_20211231_Monthly.nc\n",
    "\n",
    "'/Tumbarumba/2022_v1/L6/default/Tumbarumba_L6_20020107_20191231_Monthly.nc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site = 'AliceSpringsMulga/2022_v1/L6/default/AliceSpringsMulga_L6_20100903_20211231_Monthly.nc'\n",
    "var = ['NEE_SOLO', 'Ta', 'Fsd', 'VPD', 'Precip']\n",
    "var_names = ['NEE','Ta','solar','VPD', 'precip']\n",
    "max_lag = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VPD(rh, ta):\n",
    "    sat_vp = (6.11 * np.exp((2500000/461) * (1/273 - 1/(273 + ta))))\n",
    "    vpd = (((100 - rh)/100) * sat_vp)\n",
    "    return vpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_dataset('https://dap.tern.org.au/thredds/dodsC/ecosystem_process/ozflux/'+site)\n",
    "ds['GPP_SOLO'] = xr.where(ds.GPP_SOLO < 0, 0, ds.GPP_SOLO)  #Set negative GPP, ER, and ET measurements as zero\n",
    "df = ds.to_dataframe().reset_index(\n",
    "        level=[1, 2]).drop(['latitude', 'longitude'], axis=1)\n",
    "# calculate VPD on ec data\n",
    "df['VPD'] = VPD(df.RH, df.Ta)\n",
    "df = df[var].dropna()\n",
    "\n",
    "data = df.values\n",
    "T, N = data.shape\n",
    "\n",
    "# Initialize dataframe object, specify time axis and variable names\n",
    "dataframe = pp.DataFrame(data, \n",
    "                         datatime = {0:np.arange(len(data))}, \n",
    "                         var_names=var_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we plot the time series. This can be done with the function ``tp.plot_timeseries``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tp.plot_timeseries(dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's stationary and doesn't contain missing values (covered in other tutorial). Next, we choose a conditional independence test, here we start with ``ParCorr`` implementing linear partial correlation. With ``significance='analytic'`` the null distribution is assumed to be Student's $t$. Then we initialize the ``PCMCI`` method with  ``dataframe``, and ``cond_ind_test``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parcorr = ParCorr(significance='analytic')\n",
    "pcmci = PCMCI(\n",
    "    dataframe=dataframe, \n",
    "    cond_ind_test=parcorr,\n",
    "    verbosity=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running the causal algorithm, it's a good idea to plot the lagged unconditional dependencies, e.g., the lagged correlations. This can help to identify which maximal time lag ``tau_max`` to choose in the causal algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations = pcmci.get_lagged_dependencies(tau_max=max_lag, val_only=True)['val_matrix']\n",
    "lag_func_matrix = tp.plot_lagfuncs(val_matrix=correlations, setup_args={'var_names':var_names, \n",
    "                                    'x_base':5, 'y_base':.5});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do another check and use the new ``plot_scatterplots`` function to see whether the dependencies are really linear and ``ParCorr`` is the right conditional independence test. With the argument ``scatter_lags`` set to a ``(N, N)`` integer numpy array you can choose which lag to use for every pair of variables. Here we choose the lag at which the correlations above have their maximal absolute value. Of course, you might want to use a nonlinear conditional independence test to assess the lags with maximum dependency. I.e., run ``pcmci.get_lagged_dependencies`` with ``PCMCI`` initialized with a nonlinear measure (e.g., CMIknn or GPDC as introduced below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_lags = np.argmax(np.abs(correlations), axis=2)\n",
    "tp.plot_scatterplots(dataframe=dataframe, add_scatterplot_args={'scatter_lags':scatter_lags});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the dependencies in the lag function plot decay beyond a maximum lag of around 8, we choose ``tau_max=8`` for PCMCI. The other main parameter is ``pc_alpha`` which sets the significance level in the condition-selection step. Here we let PCMCI choose the optimal value by setting it to ``pc_alpha=None``. Then PCMCI will optimize this parameter in the ParCorr case by the Akaike Information criterion among a reasonable default list of values (e.g., ``pc_alpha = [0.05, 0.1, 0.2, 0.3, 0.4, 0.5]``). The parameter ``alpha_level=0.01`` indicates that we threshold the resulting p-value matrix at this significance level to obtain the graph. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau_max = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcmci.verbosity = 1\n",
    "results = pcmci.run_pcmci(tau_max=tau_max, pc_alpha=None, alpha_level=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see from the output, PCMCI selected different ``pc_alpha`` for each variable. The result of ``run_pcmci`` is a dictionary containing the matrix of p-values, the matrix of test statistic values (here MCI partial correlations) and optionally its confidence bounds (can be specified upon initializing ``ParCorr``), and the ``graph`` matrix. ``p_matrix`` and ``val_matrix`` are of shape ``(N, N, tau_max+1)`` with entry ``(i, j, \\tau)`` denoting the test for the link $X^i_{t-\\tau} \\to X^j_t$. The MCI values for $\\tau=0$ do not exclude other contemporaneous effects, only past variables are conditioned upon. The ``graph`` array of the same shape is obtained from thresholding the ``p_matrix`` at the specified ``alpha_level``. It is a string array and denotes significant lagged causal links by ``-->`` and contemporaneou links (where the orientation cannot be determined with PCMCI) by ``o-o``. With the PCMCIplus method also contemporaneous links can be oriented.\n",
    "\n",
    "__Note:__ The test statistic values (e.g., partial correlation) may give a qualitative intuition of the `strength` of a dependency, but for a proper causal effect analysis please refer to the ``CausalEffects`` class and tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"p-values\")\n",
    "# print (results['p_matrix'].round(3))\n",
    "# print(\"MCI partial correlations\")\n",
    "# print (results['val_matrix'].round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to control for the $N^2 \\tau_\\max$ tests conducted here, we can further correct the p-values, e.g., by False Discovery Rate (FDR) control yielding the ``q_matrix``. The graph can then be updated with that adjusted ``p_matrix`` and a different ``alpha_level`` using ``get_graph_from_pmatrix()``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_matrix = pcmci.get_corrected_pvalues(p_matrix=results['p_matrix'], tau_max=tau_max, fdr_method='fdr_bh')\n",
    "pcmci.print_significant_links(\n",
    "        p_matrix = q_matrix,\n",
    "        val_matrix = results['val_matrix'],\n",
    "        alpha_level = 0.01)\n",
    "graph = pcmci.get_graph_from_pmatrix(p_matrix=q_matrix, alpha_level=0.01, \n",
    "            tau_min=0, tau_max=tau_max, selected_links=None)\n",
    "results['graph'] = graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tigramite offers several plotting options: The lag function matrix (as shown above), the time series graph, and the process graph which aggregates the information in the time series graph. Both take as arguments the ``graph`` array and optionally the ``val_matrix`` and further link attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the process graph, the node color denotes the auto-MCI value and the link colors the cross-MCI value. If links occur at multiple lags between two variables, the link color denotes the strongest one and the label lists all significant lags in order of their strength."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp.plot_graph(\n",
    "    figsize=(8,5),\n",
    "    val_matrix=results['val_matrix'],\n",
    "    graph=results['graph'],\n",
    "    var_names=var_names,\n",
    "    link_colorbar_label='cross-MCI',\n",
    "    node_colorbar_label='auto-MCI',\n",
    "    ); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot time series graph    \n",
    "tp.plot_time_series_graph(\n",
    "    figsize=(10, 8),\n",
    "    node_size=0.05,\n",
    "    val_matrix=results['val_matrix'],\n",
    "    graph=results['graph'],\n",
    "    var_names=var_names,\n",
    "    link_colorbar_label='MCI',\n",
    "    ); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the process graph is nicer to look at, the time series graph better represents the spatio-temporal dependency structure from which causal pathways can be read off. You can adjust the size and aspect ratio of nodes with `node_size` and `node_aspect` parameters, and also modify many other properties, see the parameters of `plot_graph` and `plot_time_series_graph`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CMIknn\n",
    "\n",
    "The most general conditional independence test implemented in Tigramite is CMIknn based on conditional mutual information estimated with a k-nearest neighbor estimator. This test is described in the paper \n",
    "\n",
    "Runge, Jakob. 2018. “Conditional Independence Testing Based on a Nearest-Neighbor Estimator of Conditional Mutual Information.” In Proceedings of the 21st International Conference on Artificial Intelligence and Statistics. \n",
    "\n",
    "CMIknn involves no assumptions about the dependencies. The parameter ``knn`` determines the size of hypercubes, ie., the (data-adaptive) local length-scale. Now we cannot even pre-compute the null distribution because CMIknn is not residual-based like GPDC and the null distribution depends on many more factors. We, therefore, use ``significance='shuffle_test'`` to generate it in each individual test. The shuffle test for testing $I(X;Y|Z)=0$ shuffles $X$ values *locally*: Each sample point $i$’s $x$-value is mapped randomly\n",
    "to one of its nearest neigbors (``shuffle_neighbors`` parameter) in subspace $Z$. Another free parameter is ``transform`` which specifies whether data is transformed before CMI estimation. The new default is ``transform=ranks`` which works better than the old ``transform=standardize``.\n",
    "The following cell may take some minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmi_knn = CMIknn(significance='shuffle_test', knn=0.1, shuffle_neighbors=5, transform='ranks')\n",
    "pcmci_cmi_knn = PCMCI(\n",
    "    dataframe=dataframe, \n",
    "    cond_ind_test=cmi_knn,\n",
    "    verbosity=2)\n",
    "results = pcmci_cmi_knn.run_pcmci(tau_max=3, pc_alpha=0.05, alpha_level = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Significant links at alpha = 0.01:\n",
    "\n",
    "#     Variable $X^0$ has 1 link(s):\n",
    "#         ($X^1$ -1): pval = 0.00000 | val = 0.284\n",
    "\n",
    "#     Variable $X^1$ has 0 link(s):\n",
    "\n",
    "#     Variable $X^2$ has 1 link(s):\n",
    "#         ($X^1$ -2): pval = 0.00000 | val = 0.242"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp.plot_graph(\n",
    "    val_matrix=results['val_matrix'],\n",
    "    graph=results['graph'],\n",
    "    var_names=var_names,\n",
    "    link_colorbar_label='cross-MCI',\n",
    "    node_colorbar_label='auto-MCI',\n",
    "    vmin_edges=0.,\n",
    "    vmax_edges = 0.3,\n",
    "    edge_ticks=0.05,\n",
    "    cmap_edges='OrRd',\n",
    "    vmin_nodes=0,\n",
    "    vmax_nodes=.5,\n",
    "    node_ticks=.1,\n",
    "    cmap_nodes='OrRd',\n",
    "    ); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here CMIknn correctly detects the true links and also unveils the spurious link. While CMIknn may now seem as the best independence test choice, we have to note that the generality comes at the cost of much lower power for the case that the dependencies actually follow some parametric form. Then ParCorr or GPDC are much more powerful measures. Of course, ParCorr also detects linear links better than GPDC. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
