{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate and fit a ML model on the EC flux tower data \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "from joblib import dump\n",
    "import multiprocessing\n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "from lightgbm import LGBMRegressor\n",
    "import lightgbm as lgbm\n",
    "import shap\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV, KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "import sys\n",
    "sys.path.append('/g/data/os22/chad_tmp/dea-notebooks/Tools')\n",
    "from dea_tools.classification import spatial_clusters\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'AUS'\n",
    "model_var = 'NEE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncpus=multiprocessing.cpu_count()\n",
    "print('ncpus = '+str(ncpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = '/g/data/os22/chad_tmp/NEE_modelling/results/training_data/'\n",
    "sites = os.listdir('/g/data/os22/chad_tmp/NEE_modelling/results/training_data/')\n",
    "\n",
    "td = []\n",
    "for site in sites:\n",
    "    if '.csv' in site:\n",
    "        xx = pd.read_csv(base+site, index_col='time', parse_dates=True)\n",
    "        xx['site'] = site[0:5]\n",
    "        td.append(xx)\n",
    "\n",
    "ts = pd.concat(td).dropna() #we'll use this later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = [\n",
    "            #'LAI_anom_RS',\n",
    "             'kNDVI_anom_RS',\n",
    "             'FPAR_RS',\n",
    "             'LST_RS',\n",
    "             'tree_cover_RS',\n",
    "             'nontree_cover_RS',\n",
    "             'nonveg_cover_RS',\n",
    "             'LST-Tair_RS',\n",
    "             'TWI_RS',\n",
    "             'NDWI_RS',\n",
    "             'rain_anom_RS',\n",
    "             'rain_cml3_anom_RS',\n",
    "             'rain_cml6_anom_RS',\n",
    "             'rain_cml12_anom_RS',\n",
    "             'srad_anom_RS',\n",
    "             'vpd_RS',\n",
    "             'tavg_anom_RS',\n",
    "             'SOC_RS',\n",
    "             #'CO2_RS',\n",
    "             'site'\n",
    "            ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.drop(['Fluxcom_RS-Meteo_NEE', 'Fluxcom_RS_NEE', 'ThisStudy_NEE', 'Cable_NEE',\n",
    "       'Fluxcom_RS_GPP', 'Fluxcom_RS-meteo_GPP', 'ThisStudy_GPP', 'Cable_GPP',\n",
    "       'MODIS_GPP', 'GOSIF_GPP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = []\n",
    "yy = []\n",
    "\n",
    "for t in td:\n",
    "    t = t.drop(['Fluxcom_RS-Meteo_NEE', 'Fluxcom_RS_NEE', 'ThisStudy_NEE', 'Cable_NEE',\n",
    "       'Fluxcom_RS_GPP', 'Fluxcom_RS-meteo_GPP', 'ThisStudy_GPP', 'Cable_GPP',\n",
    "       'MODIS_GPP', 'GOSIF_GPP'], axis=1)  \n",
    "    \n",
    "    t = t.dropna()  # remove NaNS\n",
    "    df = t.drop(['NEE_SOLO_EC','GPP_SOLO_EC','ER_SOLO_EC'], axis=1) # seperate carbon fluxes\n",
    "    \n",
    "    #df = df.filter(regex='RS') # only use remote sensing variables   \n",
    "    df = df[variables]\n",
    "    \n",
    "    if model_var == 'ET':\n",
    "        df_var=t[model_var+'_EC']\n",
    "    else:\n",
    "        df_var=t[model_var+'_SOLO_EC'] # seperate out the variable we're modelling\n",
    "    \n",
    "    x = df.reset_index(drop=True)#.to_numpy()\n",
    "    y = df_var.reset_index(drop=True)#.to_numpy()\n",
    "    xx.append(x)\n",
    "    yy.append(y)\n",
    "\n",
    "x = pd.concat(xx)\n",
    "y = pd.concat(yy)\n",
    "\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify monotonic constraints for CO2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m_con= ['1' if col == 'CO2_RS' else '0' for col in x.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "\n",
    "http://rasbt.github.io/mlxtend/user_guide/feature_selection/SequentialFeatureSelector/#sequentialfeatureselector-the-popular-forward-and-backward-feature-selection-approaches-including-floating-variants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test model robustness with time-series K-fold cross validation\n",
    "\n",
    "* If you set boosting as RF then the lightgbm algorithm behaves as random forest. According to the documentation, to use RF you must use bagging_fraction and feature_fraction smaller than 1\n",
    "\n",
    "\n",
    "<img src=\"results/figs/cross_validation.png\" width=800>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate five sets of train-test indices\n",
    "\n",
    "For each site, grab a sequential set of test samples (time-series-split methods), the remaining points (either side of test samples) go into training.  A single K-fold contains test and training samples from every site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sites = x['site'].unique()\n",
    "x['original_index'] = [i for i in range(0,len(x))]\n",
    "\n",
    "train_1=[]\n",
    "train_2=[]\n",
    "train_3=[]\n",
    "train_4=[]\n",
    "train_5=[]\n",
    "\n",
    "test_1=[]\n",
    "test_2=[]\n",
    "test_3=[]\n",
    "test_4=[]\n",
    "test_5=[]\n",
    "\n",
    "for site in sites:\n",
    "    df = x.loc[x['site'] == site]\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "    i=1\n",
    "    for train, test in tscv.split(df):\n",
    "        all_indices=np.concatenate([train,test])\n",
    "        left_over = df.loc[~df.index.isin(all_indices)].index.values\n",
    "        train = np.concatenate([train, left_over])\n",
    "        if i==1:\n",
    "            train_1.append(df.iloc[train]['original_index'].values)\n",
    "            test_1.append(df.iloc[test]['original_index'].values)\n",
    "        if i==2:\n",
    "            train_2.append(df.iloc[train]['original_index'].values)\n",
    "            test_2.append(df.iloc[test]['original_index'].values)\n",
    "        if i==3:\n",
    "            train_3.append(df.iloc[train]['original_index'].values)\n",
    "            test_3.append(df.iloc[test]['original_index'].values)\n",
    "        if i==4:\n",
    "            train_4.append(df.iloc[train]['original_index'].values)\n",
    "            test_4.append(df.iloc[test]['original_index'].values)\n",
    "        if i==4:\n",
    "            train_5.append(df.iloc[train]['original_index'].values)\n",
    "            test_5.append(df.iloc[test]['original_index'].values)\n",
    "        i+=1\n",
    "\n",
    "train_1 = np.concatenate(train_1)\n",
    "train_2 = np.concatenate(train_2)\n",
    "train_3 = np.concatenate(train_3)\n",
    "train_4 = np.concatenate(train_4)\n",
    "train_5 = np.concatenate(train_5)\n",
    "\n",
    "test_1 = np.concatenate(test_1)\n",
    "test_2 = np.concatenate(test_2)\n",
    "test_3 = np.concatenate(test_3)\n",
    "test_4 = np.concatenate(test_4)\n",
    "test_5 = np.concatenate(test_5)\n",
    "\n",
    "train = [train_1, train_2, train_3, train_4, train_5]\n",
    "test = [test_1, test_2, test_3, test_4, test_5]\n",
    "\n",
    "#check there are no train indices in the test indices\n",
    "for i,j in zip(train, test):\n",
    "    assert (np.sum(np.isin(i,j)) == 0)\n",
    "\n",
    "#remove the columns we no longer need\n",
    "x = x.drop(['site', 'original_index'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write out predictor variables to text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "textfile = open(\"/g/data/os22/chad_tmp/NEE_modelling/results/variables.txt\", \"w\")\n",
    "for element in x.columns:\n",
    "    textfile.write(element + \",\")\n",
    "textfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the parameter grid based\n",
    "param_grid = {\n",
    "    'num_leaves': [7, 14, 21, 28, 31, 50],\n",
    "    'min_child_samples':[15, 20, 30],\n",
    "    'boosting_type': ['gbdt', 'dart'],\n",
    "    'max_depth': [3, 5, 10, 20, 25],\n",
    "    'n_estimators': [200, 300, 400, 500],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lists to store results of CV testing\n",
    "acc = []\n",
    "rmse=[]\n",
    "r2=[]\n",
    "\n",
    "i = 1\n",
    "for train_index, test_index in zip(train, test):\n",
    "    print(f\"Working on {i}/{len(train)} outer cv split\", end='\\r')\n",
    "    model = LGBMRegressor(random_state=1,\n",
    "                          verbose=-1\n",
    "                          # monotone_constraints=m_con,\n",
    "                          # monotone_constraints_method='intermediate'\n",
    "                          )\n",
    "\n",
    "    # index training, testing\n",
    "    X_tr, X_tt = x.iloc[train_index, :], x.iloc[test_index, :]\n",
    "    y_tr, y_tt = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    #simple random split on inner fold\n",
    "    inner_cv = KFold(n_splits=5,\n",
    "                     shuffle=True,\n",
    "                     random_state=0)\n",
    "    \n",
    "    clf = GridSearchCV(\n",
    "        estimator=model,\n",
    "        param_grid=param_grid,\n",
    "        scoring='r2',\n",
    "        n_jobs=ncpus,\n",
    "        refit=True,\n",
    "        cv=inner_cv.split(X_tr, y_tr),\n",
    "    )\n",
    "    \n",
    "    #prevents extensive print statements\n",
    "    clf.fit(X_tr, y_tr, callbacks=None)\n",
    "    \n",
    "    # predict using the best model\n",
    "    best_model = clf.best_estimator_\n",
    "    pred = best_model.predict(X_tt)\n",
    "\n",
    "    # evaluate model w/ multiple metrics\n",
    "    # r2\n",
    "    r2_ = r2_score(y_tt, pred)\n",
    "    r2.append(r2_)\n",
    "    # MAE\n",
    "    ac = mean_absolute_error(y_tt, pred)\n",
    "    acc.append(ac)\n",
    "    # RMSE\n",
    "    rmse_ = np.sqrt(mean_squared_error(y_tt, pred))\n",
    "    rmse.append(rmse_)\n",
    "    \n",
    "    #1:1 plots for each fold (save to csv so we can make a plot later on)\n",
    "    df = pd.DataFrame({'Test':y_tt, 'Pred':pred}).reset_index(drop=True)\n",
    "    df.to_csv(\"/g/data/os22/chad_tmp/NEE_modelling/results/cross_validation/\"+str(i)+\"_\"+model_var+\"_lgbm.csv\")\n",
    "    \n",
    "    fig,ax = plt.subplots(1,1, figsize=(6,6))\n",
    "    \n",
    "    sb.scatterplot(x=y_tt,y=pred,color=\"#338844\", edgecolor=\"white\", s=50, lw=1, alpha=0.5, ax=ax)\n",
    "    sb.regplot(x=y_tt, y=pred, scatter=False, color='m', ax=ax)\n",
    "    sb.regplot(x=y_tt, y=y_tt, color='black', scatter=False, line_kws={'linestyle':'dashed'}, ax=ax);\n",
    "    \n",
    "    plt.xlabel('True')\n",
    "    plt.ylabel('Prediction');\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(\"/g/data/os22/chad_tmp/NEE_modelling/results/cross_validation/\"+str(i)+\"_\"+model_var+\"_lgbm.png\")\n",
    "    plt.close()\n",
    "    \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean MAE accuracy: \"+ str(round(np.mean(acc), 2)))\n",
    "print(\"Std dev of MAE accuracy: \"+ str(round(np.std(acc), 2)))\n",
    "print('\\n')\n",
    "print(\"Mean RMSE: \"+ str(round(np.mean(rmse), 2)))\n",
    "print(\"Std dev RMSE: \"+ str(round(np.std(rmse), 2)))\n",
    "print('\\n')\n",
    "print(\"Mean r2: \"+ str(round(np.mean(r2), 2)))\n",
    "print(\"Std dev r2: \"+ str(round(np.std(r2), 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'num_leaves': [7, 14, 21, 28, 31, 50],\n",
    "    'min_child_samples':[15, 20, 30],\n",
    "    'boosting_type': ['gbdt', 'dart'],\n",
    "    'max_depth': [3, 5, 10, 20, 25],\n",
    "    'n_estimators': [200, 300, 400, 500],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate n_splits of train-test_split\n",
    "#rs = ShuffleSplit(n_splits=outer_cv_splits, test_size=test_size, random_state=1)\n",
    "\n",
    "#instatiate a gridsearchCV\n",
    "clf = GridSearchCV(LGBMRegressor(verbose=-1\n",
    "                                 # boosting_type='rf',\n",
    "                                 # bagging_freq=1, \n",
    "                                 # bagging_fraction=0.8\n",
    "                                ),\n",
    "                   param_grid,\n",
    "                   scoring='r2',\n",
    "                   verbose=1,\n",
    "                   cv=zip(train, test), #using timeseries custom splits here\n",
    "                  )\n",
    "\n",
    "clf.fit(x, y, callbacks=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The most accurate combination of tested parameters is: \")\n",
    "pprint(clf.best_params_)\n",
    "print('\\n')\n",
    "print(\"The MAPE  score using these parameters is: \")\n",
    "print(round(clf.best_score_, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit on all data using best params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LGBMRegressor(**clf.best_params_)\n",
    "\n",
    "model.fit(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit upper and lower quantile models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lower = LGBMRegressor(objective='quantile', alpha=0.05, **clf.best_params_)\n",
    "model_lower.fit(x,y)\n",
    "\n",
    "model_upper = LGBMRegressor(objective='quantile', alpha=0.95, **clf.best_params_)\n",
    "model_upper.fit(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(model, '/g/data/os22/chad_tmp/NEE_modelling/results/models/'+model_name+'_'+model_var+'_LGBM_model.joblib')\n",
    "dump(model_lower, '/g/data/os22/chad_tmp/NEE_modelling/results/models/'+model_name+'_'+model_var+'_LGBM_model_lower.joblib')\n",
    "dump(model_upper, '/g/data/os22/chad_tmp/NEE_modelling/results/models/'+model_name+'_'+model_var+'_LGBM_model_upper.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict on all the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x)\n",
    "\n",
    "rmse = float(format(np.sqrt(mean_squared_error(y, y_pred)), '.3f'))\n",
    "print(\"RMSE:\", rmse);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.scatterplot(x=y,y=y_pred,color=\"#338844\", edgecolor=\"white\", s=50, lw=1, alpha=0.5)\n",
    "sb.regplot(x=y, y=y_pred, scatter=False, color='m')\n",
    "sb.regplot(x=y, y=y, color='black', scatter=False, line_kws={'linestyle':'dashed'});\n",
    "plt.xlabel('True')\n",
    "plt.ylabel('Prediction');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine feature importance\n",
    "\n",
    "SHAP (SHapley Additive exPlanations) is a game theoretic approach to explain the output of any machine learning model\n",
    "\n",
    "https://github.com/slundberg/shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explain the model's predictions using SHAP\n",
    "explainer = shap.Explainer(model)\n",
    "shap_values = explainer(x)\n",
    "\n",
    "# visualize the first prediction's explanation\n",
    "# shap.plots.waterfall(shap_values[0])\n",
    "# shap.plots.beeswarm(shap_values)\n",
    "shap.plots.bar(shap_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict the sites time-series to compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for site in sites:\n",
    "    print(site)\n",
    "    df = ts.loc[ts['site'] == site]\n",
    "    df = df.dropna()\n",
    "    if model_var == 'ET':\n",
    "        df_y=df[model_var+'_EC']\n",
    "    else:\n",
    "        df_y=df[model_var+'_SOLO_EC'] # seperate out the variable we're modelling\n",
    "   \n",
    "    df_x = df[variables]\n",
    "    df_x = df_x.drop('site', axis=1)\n",
    "    \n",
    "    x = df_x.reset_index(drop=True)#.to_numpy()\n",
    "    y = df_y.reset_index(drop=True)#.to_numpy()\n",
    "\n",
    "    y_pred = model.predict(x)\n",
    "\n",
    "    rmse = float(format(np.sqrt(mean_squared_error(y, y_pred)), '.3f'))\n",
    "    r2_ = r2_score(y, y_pred)\n",
    "    \n",
    "    #Compare time-series in a plot\n",
    "    df_y_true = df[[model_var+'_SOLO_EC']]\n",
    "    df_y_true['pred_'+model_var] = y_pred \n",
    "    \n",
    "    sb.set_style(\"darkgrid\")\n",
    "    fig,ax = plt.subplots(1,1, figsize=(12,5))\n",
    "    sb.lineplot(x='time', y=model_var+'_SOLO_EC', data=df_y_true, color=\"green\", linewidth=1, ax=ax)\n",
    "    sb.lineplot(x='time', y='pred_'+model_var, data=df_y_true, color=\"blue\", linewidth=1, ax=ax)\n",
    "\n",
    "    ax.text(.015, .95, 'r = {:.3f}'.format(r2_),\n",
    "            transform=ax.transAxes)\n",
    "    ax.text(.015, .9, 'mae = {:.3g}'.format(ac),\n",
    "            transform=ax.transAxes)\n",
    "\n",
    "    ax.set_ylabel(model_var)\n",
    "    ax.set_xlabel(None)\n",
    "    ax.set_title(site+': '+model_var + ' Cross Validation Results')\n",
    "    plt.legend(labels=[\"True\",\"Prediction\"], loc='lower left')\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(\"/g/data/os22/chad_tmp/NEE_modelling/results/timeseries_predict/\"+site+\"_\"+model_var+\"_LGBM.png\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
