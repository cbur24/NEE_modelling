{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collecting various gridded datasets to use as predictors in a NEE model\n",
    "\n",
    "- ANU climate data\n",
    "- MODIS LAI\n",
    "- Soil moisture from GRAFS\n",
    "\n",
    "Results are saved to `/g/data/os22/chad_tmp/NEE_modelling/results/input_data/input_data_<YYYY>.nc`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install xarray\n",
    "# !pip install datacube\n",
    "# !pip install --extra-index-url=\"https://packages.dea.ga.gov.au\" \\\n",
    "#   odc-algo\n",
    "\n",
    "# !pip install rioxarray\n",
    "# !pip install odc-geo\n",
    "# !pip install dea_tools\n",
    "# !pip install joblib\n",
    "# !pip install tqdm\n",
    "# !pip install geopandas\n",
    "# !pip install -U scikit-learn\n",
    "# !pip install dask-ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import odc.geo.xr\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from odc.algo import xr_reproject\n",
    "from odc.geo.xr import assign_crs\n",
    "\n",
    "import sys\n",
    "sys.path.append('/g/data/os22/chad_tmp/NEE_modelling/')\n",
    "from collect_gridded_data import collect_gridded_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datacube.utils.dask import start_local_dask\n",
    "client = start_local_dask(mem_safety_margin='2Gb')\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time=('2015')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "collect_gridded_data(time=time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "# Collecting and processing various datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resampling GRAFS and LAI to monthly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# client = start_local_dask(mem_safety_margin='1Gb')\n",
    "# client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "for y in range(2018, 2022):\n",
    "    print(\" {:03}/{:03}\\r\".format(i + 1, len(range(2018, 2022))), end=\"\")\n",
    "    \n",
    "    year = str(y)\n",
    "    \n",
    "    sws = xr.open_dataset('/g/data/fj4/SatelliteSoilMoistureProducts/S-GRAFS/ANNUAL_NC/surface_soil_moisture_vol_1km_'+year+'.nc',\n",
    "                      chunks=dict(lat=1000, lon=1000))\n",
    "    sws = assign_crs(sws, crs=sws.attrs['crs'][-9:])\n",
    "    sws = sws.soil_moisture.where(sws >=0)\n",
    "    sws = sws.soil_moisture.resample(time='MS', loffset=pd.Timedelta(14, 'd')).mean().compute()\n",
    "    sws = sws.rename({'lat':'latitude', 'lon':'longitude'})\n",
    "    sws.to_netcdf('/g/data/os22/chad_tmp/NEE_modelling/data/GRAFS/GRAFS_1km_monthly_'+year+'.nc')\n",
    "    i+=1\n",
    "    \n",
    "i=0\n",
    "for y in range(2016, 2022):\n",
    "    print(\" {:03}/{:03}\\r\".format(i + 1, len(range(2016, 2022))), end=\"\")\n",
    "    \n",
    "    year = str(y)\n",
    "    \n",
    "    base = '/g/data/ub8/au/MODIS/mosaic/MOD15A2H.006/'\n",
    "    lai = xr.open_dataset('/g/data/ub8/au/MODIS/mosaic/MOD15A2H.006/MOD15A2H.006.b02.500m_lai.'+year+'.nc',\n",
    "                          chunks=dict(latitude=1000, longitude=1000))\n",
    "    lai = assign_crs(lai, crs='epsg:4326')\n",
    "    lai = lai['500m_lai'].rename('lai') #tidy up the dataset\n",
    "    lai = lai.where((lai <= 10) & (lai >=0)) #remove artefacts and 'no-data'\n",
    "    lai = lai.resample(time='MS', loffset=pd.Timedelta(14, 'd')).mean().compute() # resample to monthly\n",
    "    lai.to_netcdf('/g/data/os22/chad_tmp/NEE_modelling/data/LAI/LAI_500m_monthly_'+year+'.nc')\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stitch together GO-SIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import rioxarray\n",
    "from odc.geo.xr import assign_crs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base='/g/data/os22/chad_tmp/NEE_modelling/data/SIF/GOSIF/'\n",
    "\n",
    "arrs=[]\n",
    "files = os.listdir(base)\n",
    "i = 0\n",
    "for f in files:\n",
    "    print(\" Tif {:03}/{:03}\\r\".format(i + 1, len(files)), end=\"\")\n",
    "    if f.endswith('.tif'):\n",
    "        y=f[-12:-8]\n",
    "        m=f[-6:-4]\n",
    "        sif = rioxarray.open_rasterio(base+f).squeeze().drop('band')\n",
    "        sif = assign_crs(sif, crs='epsg:4326')\n",
    "        time=pd.date_range(np.datetime64(y+'-'+m), periods=1, freq=\"MS\") + pd.Timedelta(14, 'd')\n",
    "        sif = sif.expand_dims(time=time) \n",
    "        sif = sif.where(sif < 32766) # clean up dataset\n",
    "        sif = sif.sel(x=slice(110,155)).sel(y=slice(-8,-45)).astype('float32') #Australia only\n",
    "        arrs.append(sif)\n",
    "        i += 1\n",
    "        \n",
    "sif = xr.concat(arrs, dim='time').sortby('time')\n",
    "sif = xr.where(sif < 0, 0, sif) #replace -ve values with 0\n",
    "sif.name = 'SIF'\n",
    "sif.to_netcdf('/g/data/os22/chad_tmp/NEE_modelling/data/SIF/GOSIF_2000_2020.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODIS Land surface temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base='/g/data/ub8/au/MODIS/mosaic/MYD11A1.006/'\n",
    "files = os.listdir(base)\n",
    "paths = [base+i for i in files if not 'QC' in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in paths:\n",
    "    y=p[-7:-3] #year\n",
    "    lst = xr.open_dataset('/g/data/ub8/au/MODIS/mosaic/MYD11A1.006/MYD11A1.006.LST_Day_1km.2020.nc',\n",
    "                          chunks=dict(latitude=1000, longitude=1000))\n",
    "    lst = assign_crs(lst, crs='epsg:4326')\n",
    "    lst = lst.resample(time='MS', loffset=pd.Timedelta(14, 'd')).mean().compute()\n",
    "    lst = lst.LST_Day_1km.rename('LST')\n",
    "    lst.to_netcdf('/g/data/os22/chad_tmp/NEE_modelling/data/LST/LST_'+y+'.nc')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODIS fPAR from GEE\n",
    "\n",
    "https://github.com/aazuspan/wxee/blob/main/docs/examples/image_collection_to_xarray.ipynb\n",
    "\n",
    "https://github.com/aazuspan/wxee/blob/main/docs/examples/modis.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install earthengine-api\n",
    "# !pip install wxee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "import wxee\n",
    "import xarray as xr\n",
    "import rioxarray\n",
    "from odc.geo.xr import assign_crs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from odc.algo import xr_reproject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trigger the authentication flow.\n",
    "ee.Authenticate()\n",
    "\n",
    "# Initialize the library.\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ~Aus region (slightly less to trick google into giving me 1km res)\n",
    "region = ee.Geometry.Polygon([[\n",
    "            [114,-43.0],\n",
    "            [153.0,-43.0],\n",
    "            [153.0,-10.0],\n",
    "            [114,-10.0],\n",
    "            [114,-43.0]]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop through months and resample 4-day fPAR MODIS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use start and end dates to loop through months and load GEE FPAR data\n",
    "start = pd.date_range(start='7/1/2002', end='12/1/2021', freq='MS') \n",
    "end = pd.date_range(start='7/1/2002', end='12/31/2021', freq='M')\n",
    "\n",
    "i = 0\n",
    "for s, e in zip(start,end):\n",
    "    \n",
    "    print(\" {:03}/{:03}\\r\".format(i + 1, len(start)), end=\"\")\n",
    "    \n",
    "    #use this to check if file already exists\n",
    "    ss = s+pd.Timedelta(14, 'd')\n",
    "    if os.path.isfile('/g/data/os22/chad_tmp/NEE_modelling/data/FPAR/FPAR_'+ss.strftime('%Y-%m-%d')+'.nc'):\n",
    "        pass\n",
    "    \n",
    "    else:\n",
    "        try:\n",
    "            s = s.strftime('%Y-%m-%d')\n",
    "            e = e.strftime('%Y-%m-%d')\n",
    "\n",
    "            #download data from GEE\n",
    "            ts = wxee.TimeSeries(\"MODIS/061/MCD15A3H\").filterDate(s, e)\n",
    "            ts = ts.select([\"Fpar\"])\n",
    "            ds = ts.wx.to_xarray(region=region, scale=1000, crs=\"EPSG:3577\", progress=False) #download at 1km res\n",
    "\n",
    "            attrs=ds.attrs #extract attributes so we don't loose them\n",
    "            ds = assign_crs(ds, crs='epsg:3577') #add geobox\n",
    "            ds = ds.resample(time='MS', loffset=pd.Timedelta(14, 'd')).mean() #resample to monthly\n",
    "            ds = ds.Fpar #convert to dataarray\n",
    "\n",
    "            lst = xr.open_dataarray('/g/data/os22/chad_tmp/NEE_modelling/data/LST/LST_2002.nc').isel(time=0) #use this to reproject too\n",
    "            ds = xr_reproject(ds, geobox=lst.geobox, resampling='bilinear') #reproject\n",
    "            ds = ds.where(ds!=0) # remove spurious zeros from reprojection\n",
    "            ds = ds.assign_attrs(attrs) #add back attrs\n",
    "            ds.to_netcdf('/g/data/os22/chad_tmp/NEE_modelling/data/FPAR/FPAR_'+np.datetime_as_string(ds.time.values[0], unit='D')+'.nc')\n",
    "\n",
    "        except:\n",
    "            print('fail:', s,e)\n",
    "            pass\n",
    "        \n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stitch together monthly files into annual netcdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base='/g/data/os22/chad_tmp/NEE_modelling/data/FPAR/'\n",
    "i=0\n",
    "for y in range(2002, 2022):\n",
    "    print(\" {:03}/{:03}\\r\".format(i + 1, len(range(2002, 2023))), end=\"\")\n",
    "    \n",
    "    year = str(y)\n",
    "    files = [base+f for f in os.listdir(base) if year in f]\n",
    "    \n",
    "    dss=[]\n",
    "    for f in files:\n",
    "        ds = xr.open_dataset(f)\n",
    "        dss.append(ds)\n",
    "        \n",
    "    data = xr.concat(dss, dim='time').sortby('time')\n",
    "    data.to_netcdf('/g/data/os22/chad_tmp/NEE_modelling/data/FPAR_annual/FPAR_MODIS_1km_'+year+'.nc')\n",
    "    \n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Himawari 8 Solar\n",
    "\n",
    "/g/data/fj8/BoM/AWRA/DATA/CLIMATE/solar_exposure_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard precipitation index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install zarr\n",
    "# !pip install climate_indices\n",
    "# from climate_indices import compute,indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create long time-series of rainfall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base='/g/data/gh70/ANUClimate/v2-0/stable/month/'\n",
    "years = [str(i) for i in range(2002,2021)]\n",
    "\n",
    "pp = []\n",
    "for y in years:\n",
    "    precip = xr.open_mfdataset([base+'rain/'+y+'/'+i for i in os.listdir(base+'rain/'+y+'/')],\n",
    "                              chunks=dict(lat=1000, lon=1000))\n",
    "    precip = assign_crs(precip, crs='epsg:4283') #GDA94\n",
    "    precip = precip.drop('crs').rain\n",
    "    # precip = precip.rename({'lat':'latitude', 'lon':'longitude'})\n",
    "    pp.append(precip)\n",
    "\n",
    "precip = xr.concat(pp, dim='time').sortby('time')\n",
    "del precip.attrs['grid_mapping']\n",
    "precip.attrs['units'] = 'mm'\n",
    "precip = precip.to_dataset()\n",
    "precip.to_zarr('/g/data/os22/chad_tmp/NEE_modelling/data/SPI/rainfall_2002_2020.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use `climate_indices` command line to calculate SPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scales= < 6 produces NaNs in some places\n",
    "import os\n",
    "os.system(\"process_climate_indices \"\\\n",
    "       \"--index spi \"\\\n",
    "       \"--periodicity monthly \"\\\n",
    "       \"--netcdf_precip /g/data/os22/chad_tmp/NEE_modelling/data/SPI/ANUClim_rainfall_2002_2020.nc \"\\\n",
    "       \"--var_name_precip rain \"\\\n",
    "       \"--output_file_base /g/data/os22/chad_tmp/NEE_modelling/data/SPI/ANUClim \"\\\n",
    "       \"--scales 12 \"\\\n",
    "       \"--calibration_start_year 2002 \"\\\n",
    "       \"--calibration_end_year 2020 \"\\\n",
    "       \"--multiprocessing all \"\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spi6 = xr.open_dataset('/g/data/os22/chad_tmp/NEE_modelling/data/SPI/ANUClim_spi_gamma_06.nc').sel(time='2019')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spi6.spi_gamma_06.plot.imshow(col='time', col_wrap=4, cmap='RdBu');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Im memory xarray processing of SPI, this works but is slow (but so is the command line...)\n",
    "\n",
    "# precip_stacked = precip.stack(point=('latitude','longitude')).groupby('point') #.chunk(dict(time=-1, point=1000000))\n",
    "\n",
    "# # apply SPI to each `point`\n",
    "# scale = 6\n",
    "# distribution = indices.Distribution.gamma\n",
    "# data_start_year = 2000\n",
    "# calibration_year_initial = 2000\n",
    "# calibration_year_final = 2000\n",
    "# periodicity = compute.Periodicity.monthly\n",
    "\n",
    "# da_spi = xr.apply_ufunc(indices.spi,\n",
    "#                         precip_stacked,\n",
    "#                         scale,\n",
    "#                         distribution,\n",
    "#                         data_start_year,\n",
    "#                         calibration_year_initial,\n",
    "#                         calibration_year_final,\n",
    "#                         periodicity,\n",
    "#                         input_core_dims=[[\"time\", \"point\"],[],[],[],[],[],[]],\n",
    "#                         output_core_dims=[[\"time\"]],\n",
    "#                         # dask='allowed'\n",
    "#                        )\n",
    "\n",
    "# unstack the array back into original dimensions\n",
    "# da_spi = da_spi.unstack('point')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AWRA Climate\n",
    "\n",
    "/g/data/fj8/BoM/AWRA/DATA/CLIMATE/g/data/fj8/BoM/AWRA/DATA/CLIMATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "from odc.geo.xr import assign_crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var='solar_exposure_day'\n",
    "\n",
    "aa = []\n",
    "for y in range(2000, 2022):\n",
    "    year = str(y)\n",
    "    ds = xr.open_dataset('/g/data/fj8/BoM/AWRA/DATA/CLIMATE/'+var+'/'+var+'_'+year+'.nc')\n",
    "    ds = assign_crs(ds, crs='epsg:4236')\n",
    "    ds = ds / 0.0864 #convert to W/m2\n",
    "    ds = ds.resample(time='MS', loffset=pd.Timedelta(14, 'd')).mean()\n",
    "    aa.append(ds)\n",
    "    \n",
    "ds = xr.concat(aa, dim='time').sortby('time')\n",
    "ds.to_netcdf('/g/data/os22/chad_tmp/NEE_modelling/data/AWRA_Climate/solar_monthly_wm2_2000_2022.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "var='rain_day'\n",
    "\n",
    "aa = []\n",
    "for y in range(1991, 2022):\n",
    "    year = str(y)\n",
    "    ds = xr.open_dataset('/g/data/fj8/BoM/AWRA/DATA/CLIMATE/'+var+'/'+var+'_'+year+'.nc')\n",
    "    ds = assign_crs(ds, crs='epsg:4236')\n",
    "    ds = ds.resample(time='MS', loffset=pd.Timedelta(14, 'd')).sum()\n",
    "    aa.append(ds)\n",
    "    \n",
    "ds = xr.concat(aa, dim='time').sortby('time')\n",
    "ds.to_netcdf('/g/data/os22/chad_tmp/NEE_modelling/data/AWRA_Climate/rain_monthly_1991_2022.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FLUXCOM\n",
    "\n",
    "Downloaded from https://www.bgc-jena.mpg.de/geodb/projects/DataDnld.php\n",
    "\n",
    "Using RS-METEO driven by ERA5, ensemble of three ML models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "from matplotlib import pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = '/g/data/os22/chad_tmp/NEE_modelling/data/FLUXCOM/NEE/'\n",
    "files = os.listdir(base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nee = xr.open_mfdataset([base+f for f in files])\n",
    "nee = nee.drop(['lat_bnds','lon_bnds','time_bnds']) # clean up\n",
    "nee = nee.sel(lon=slice(110,155), lat=slice(-9,-45)) # clip to Aus\n",
    "nee.to_netcdf('/g/data/os22/chad_tmp/NEE_modelling/data/FLUXCOM/nee_rs_meteo_era5.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Canopy Height\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rioxarray\n",
    "import xarray as xr\n",
    "from odc.algo import xr_reproject\n",
    "from odc.geo.xr import assign_crs\n",
    "from datacube.utils.dask import start_local_dask\n",
    "\n",
    "client = start_local_dask(mem_safety_margin='2Gb')\n",
    "print(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = rioxarray.open_rasterio('/g/data/os22/chad_tmp/NEE_modelling/data/forest_height/Forest_height_2019_AUS.tif').squeeze().drop('band')\n",
    "ds = assign_crs(ds, crs='epsg:4236')\n",
    "ds = ds.rename({'y':'latitude', 'x':'longitude'})\n",
    "ds = ds.chunk(dict(latitude=1000,longitude=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open a dataset to get geobox to project too (1 km resolution)\n",
    "lst = xr.open_dataset('/g/data/os22/chad_tmp/NEE_modelling/data/LST/LST_2019.nc').isel(time=0)\n",
    "lst = lst.chunk(dict(latitude=1000,longitude=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr_reproject(ds, geobox=lst.geobox, resampling='average').compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.name = 'forest_height_AUS'\n",
    "\n",
    "ds.to_netcdf('/g/data/os22/chad_tmp/NEE_modelling/data/forest_height/Forest_height_1km_2019_AUS.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
