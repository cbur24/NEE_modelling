{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring flux data and environmental covariables\n",
    "\n",
    "tern data: https://portal.tern.org.au/#/d0436eef"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install dea-tools\n",
    "# !pip install odc-algo==0.2.2\n",
    "# !pip install mlforecast\n",
    "# !pip install dask_ml==1.9.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import seaborn as sb\n",
    "from joblib import dump\n",
    "from pprint import pprint\n",
    "import multiprocessing\n",
    "\n",
    "from datacube.utils.dask import start_local_dask\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV, ShuffleSplit, KFold\n",
    "\n",
    "import sys\n",
    "sys.path.append('/g/data/os22/chad_tmp/NEE_modelling/')\n",
    "# from preprocess_input_data import preprocess_data_insitu\n",
    "from preprocess_input_data import preprocess_data_gridded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = start_local_dask(mem_safety_margin='2Gb')\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'AUS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncpus=multiprocessing.cpu_count()\n",
    "print('ncpus = '+str(ncpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ~ EBF \n",
    "aa = preprocess_data_insitu('Tumbarumba/2021_v1/L6/default/Tumbarumba_L6_20020107_20191231_Monthly.nc')\n",
    "bb = preprocess_data_insitu('CumberlandPlain/2022_v1/L6/default/CumberlandPlain_L6_20140101_20220101_Monthly.nc')\n",
    "cc = preprocess_data_insitu('Whroo/2021_v1/L6/default/Whroo_L6_20111201_20210724_Monthly.nc')\n",
    "dd = preprocess_data_insitu('WombatStateForest/2022_v1/L6/default/WombatStateForest_L6_20100120_20210529_Monthly.nc')\n",
    "ee = preprocess_data_insitu('WallabyCreek/2022_v1/L6/default/WallabyCreek_L6_20050825_20130409_Monthly.nc') # fire in 2010\n",
    "\n",
    "# tropical forest\n",
    "ff =  preprocess_data_insitu('RobsonCreek/2022_v1/L6/default/RobsonCreek_L6_20130801_20211218_Monthly.nc') \n",
    "gg =  preprocess_data_insitu('CapeTribulation/2022_v1/L6/default/CapeTribulation_L6_20100101_20181102_Monthly.nc')\n",
    "\n",
    "#Savannah/woody-savannah \n",
    "hh = preprocess_data_insitu('AliceSpringsMulga/2022_v1/L6/default/AliceSpringsMulga_L6_20100903_20211231_Monthly.nc')\n",
    "ii = preprocess_data_insitu('CalperumChowilla/2022_v1/L6/default/Calperum_L6_20100730_20220216_Monthly.nc')\n",
    "jj = preprocess_data_insitu('DryRiver/2022_v1/L6/default/DryRiver_L6_20091025_20220218_Monthly.nc')\n",
    "kk = preprocess_data_insitu('Litchfield/2021_v1/L6/default/Litchfield_L6_20150623_20210725_Monthly.nc')\n",
    "ll = preprocess_data_insitu('Gingin/2021_v1/L6/default/Gingin_L6_20111013_20201231_Monthly.nc')\n",
    "\n",
    "# grasslands\n",
    "mm = preprocess_data_insitu('TiTreeEast/2022_v1/L6/default/TiTreeEast_L6_20120718_20220117_Monthly.nc')\n",
    "nn = preprocess_data_insitu('SturtPlains/2021_v1/L6/default/SturtPlains_L6_20080828_20210724_Monthly.nc')\n",
    "oo = preprocess_data_insitu('RiggsCreek/2022_v1/L6/default/RiggsCreek_L6_20110101_20170712_Monthly.nc') # pasture\n",
    "pp = preprocess_data_insitu('DalyPasture/2022_v1/L6/default/DalyPasture_L6_20080101_20130908_Monthly.nc')# pasture\n",
    "qq = preprocess_data_insitu('Otway/2021_v1/L6/default/Otway_L6_20070811_20110101_Monthly.nc')\n",
    "\n",
    "# croplands\n",
    "\n",
    "#soil site\n",
    "# dd = preprocess_data(base, 'Yanco/2021_v1/L6/default/Yanco_L6_20130101_20210724_Monthly.nc')\n",
    "\n",
    "#COLLIE SITE AT Level 5\n",
    "# 'ozflux/Collie/2021_v1/L5/default/Collie_L5_20170804_20191111.nc'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write out predictior variables to text file\n",
    "\n",
    "Will use these later to ensure input data Dataset is in the correct order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = list(aa.columns[1:])\n",
    "\n",
    "textfile = open(\"/g/data/os22/chad_tmp/NEE_modelling/results/variables.txt\", \"w\")\n",
    "for element in col:\n",
    "    textfile.write(element + \",\")\n",
    "textfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sites=[aa,bb,cc,dd,ee,ff,gg,hh,ii,jj,kk,ll,mm,nn,oo,pp,qq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = []\n",
    "yy = []\n",
    "for site in sites:\n",
    "    df_var=site.drop('NEE_SOLO', axis=1) \n",
    "    df_nee=site['NEE_SOLO']\n",
    "    x = df_var.reset_index(drop=True).to_numpy()\n",
    "    y = df_nee.reset_index(drop=True).to_numpy()\n",
    "    xx.append(x)\n",
    "    yy.append(y)\n",
    "\n",
    "x = np.concatenate([x for x in xx])\n",
    "y = np.concatenate([y for y in yy])\n",
    "\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test model robustness with nested K-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inner_cv_splits = 5\n",
    "\n",
    "outer_cv_splits = 5\n",
    "\n",
    "test_size = 0.20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'criterion': [\"squared_error\", \"absolute_error\"],\n",
    "    'max_features': ['auto', 'log2', None],\n",
    "    'n_estimators': [200,300,400]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outer_cv = KFold(n_splits=outer_cv_splits, shuffle=True,\n",
    "                        random_state=0)\n",
    "\n",
    "# lists to store results of CV testing\n",
    "acc = []\n",
    "rmse=[]\n",
    "r2=[]\n",
    "i = 1\n",
    "for train_index, test_index in outer_cv.split(x, y):\n",
    "    print(f\"Working on {i}/5 outer cv split\", end='\\r')\n",
    "    model = RandomForestRegressor(random_state=1, n_jobs=ncpus)\n",
    "\n",
    "    # index training, testing, and coordinate data\n",
    "    X_tr, X_tt = x[train_index, :], x[test_index, :]\n",
    "    y_tr, y_tt = y[train_index], y[test_index]\n",
    "    \n",
    "    # inner split on data within outer split\n",
    "    inner_cv = KFold(n_splits=inner_cv_splits,\n",
    "                     shuffle=True,\n",
    "                     random_state=0)\n",
    "    \n",
    "    clf = GridSearchCV(\n",
    "        estimator=model,\n",
    "        param_grid=param_grid,\n",
    "        scoring='r2',\n",
    "        n_jobs=ncpus,\n",
    "        refit=True,\n",
    "        cv=inner_cv.split(X_tr, y_tr),\n",
    "    )\n",
    "\n",
    "    clf.fit(X_tr, y_tr)\n",
    "    # predict using the best model\n",
    "    best_model = clf.best_estimator_\n",
    "    pred = best_model.predict(X_tt)\n",
    "\n",
    "    # evaluate model w/ multiple metrics\n",
    "    # r2\n",
    "    r2_ = r2_score(y_tt, pred)\n",
    "    r2.append(r2_)\n",
    "    # Overall accuracy\n",
    "    ac = mean_absolute_error(y_tt, pred)\n",
    "    acc.append(ac)\n",
    "    # F1 scores\n",
    "    rmse_ = np.sqrt(mean_squared_error(y_tt, pred))\n",
    "    rmse.append(rmse_)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean MAE accuracy: \"+ str(round(np.mean(acc), 2)))\n",
    "print(\"Std dev of MAE accuracy: \"+ str(round(np.std(acc), 2)))\n",
    "print('\\n')\n",
    "print(\"Mean RMSE: \"+ str(round(np.mean(rmse), 2)))\n",
    "print(\"Std dev RMSE: \"+ str(round(np.std(rmse), 2)))\n",
    "print('\\n')\n",
    "print(\"Mean r2: \"+ str(round(np.mean(r2), 2)))\n",
    "print(\"Std dev r2: \"+ str(round(np.std(r2), 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate n_splits of train-test_split\n",
    "rs = ShuffleSplit(n_splits=outer_cv_splits, test_size=test_size, random_state=0)\n",
    "\n",
    "#instatiate a gridsearchCV\n",
    "clf = GridSearchCV(RandomForestRegressor(),\n",
    "                   param_grid,\n",
    "                   scoring='r2',\n",
    "                   verbose=1,\n",
    "                   cv=rs.split(x, y),\n",
    "                   n_jobs=ncpus)\n",
    "\n",
    "clf.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The most accurate combination of tested parameters is: \")\n",
    "pprint(clf.best_params_)\n",
    "print('\\n')\n",
    "print(\"The r2 score using these parameters is: \")\n",
    "print(round(clf.best_score_, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit on all data using best params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(**clf.best_params_, random_state=1, n_jobs=ncpus)\n",
    "model.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order = np.argsort(model.feature_importances_)\n",
    "\n",
    "plt.figure(figsize=(15,4))\n",
    "plt.bar(x=np.array(df_var.columns.values)[order],\n",
    "        height=model.feature_importances_[order])\n",
    "plt.gca().set_ylabel('Importance', labelpad=10)\n",
    "plt.gca().set_xlabel('Feature', labelpad=10)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(model, '/g/data/os22/chad_tmp/NEE_modelling/results/'+model_name+'_NEE_model.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict on all the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x)\n",
    "\n",
    "rmse = float(format(np.sqrt(mean_squared_error(y, y_pred)), '.3f'))\n",
    "print(\"RMSE:\", rmse);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare at site 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare = pd.DataFrame(data=y_pred[0:len(aa)], index=aa.index).rename({0:'NEE_pred'}, axis=1)\n",
    "aa.join(compare).plot(y=['NEE_LT', 'NEE_pred'], figsize=(11,5))\n",
    "plt.title('Prediction of NEE using RF Regressor');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare at site 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare = pd.DataFrame(data=y_pred[len(aa):len(aa)+len(bb)], index=bb.index).rename({0:'NEE_pred'}, axis=1)\n",
    "bb.join(compare).plot(y=['NEE_LT', 'NEE_pred'], figsize=(11,5))\n",
    "plt.title('Prediction of NEE using RF Regressor');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Leave one out: Predict, then compare on site not included in training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=olo.drop('NEE_LT', axis=1) # predictors\n",
    "y=olo['NEE_LT'] # target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare = pd.DataFrame(data=y_pred, index=olo.index).rename({0:'NEE_pred'}, axis=1)\n",
    "olo.join(compare).plot(y=['NEE_LT', 'NEE_pred'], figsize=(11,5))\n",
    "plt.title('Prediction of NEE using RF Regressor trained on other sites');\n",
    "\n",
    "rmse = float(format(np.sqrt(mean_squared_error(y, y_pred)), '.3f'))\n",
    "print(\"RMSE:\", rmse);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import mlforecast as mlf\n",
    "# from mlforecast.core import TimeSeries\n",
    "# from mlforecast.forecast import Forecast\n",
    "# from mlforecast.distributed.models.xgb import XGBForecast\n",
    "# import dask.dataframe as dd\n",
    "# from mlforecast.distributed.forecast import DistributedForecast\n",
    "# from window_ops.expanding import expanding_mean\n",
    "# from window_ops.rolling import rolling_mean\n",
    "\n",
    "# from statsmodels.tsa.vector_ar.var_model import VAR\n",
    "# from statsmodels.tsa.stattools import adfuller\n",
    "# from statsmodels.tools.eval_measures import rmse\n",
    "# from statsmodels.tsa.stattools import grangercausalitytests"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
